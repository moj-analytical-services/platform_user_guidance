[
["index.html", "Platform Guidance About this guidance", " Platform Guidance MoJ Analytical Services 2018-02-22 About this guidance This guidance provides information about how the use the various features of the Analytical Platform. Please use the contents navigation bar on the left to find what you’re looking for, or click the magnifying glass icon above to search the guidance. Some online training recommendations are provided throughout. Platform is in early development The platform is being actively developed. We have given early access to the platform in order to receive feedback from the users. Please get in contact to tell us what you like, what you don’t like, and what doesn’t work. For bugs and problem reports, please raise a ticket via Github, here. For immediate support, contact us by email, or on the #analytical_platform Slack channel If you find any issues with the guidance, please report them here. "],
["quick-start.html", "Part 1 Quick Start 1.1 What is the Analytical Platform? 1.2 Why should I use the Analytical Platform? 1.3 FAQ: How do I? 1.4 Contacting us", " Part 1 Quick Start 1.1 What is the Analytical Platform? The Platform provides four main services to analysts: Access to analytical software. Data storage and access to datasets. The ability to create and share interactive data products and websites. Collaboration tools for analysts that enable teams to work concurrently on complex analytical projects, and perform QA incrementally. 1.1.1  Links to components of the Analytical Platform R Studio: Gives you access to R, a popular data analysis package. When using the platform, you’ll spend much of your time in R Studio. Each user has access to R Studio using a personal URL. The address is in the following format: https://YOUR_GITHUB_USERNAME-rstudio.tools.alpha.mojanalytics.xyz Amazon S3: Shared data storage for large data sets. You upload secure data to folders, with no limit on storage space. S3 uses the term ‘buckets’ for folders. Jenkins: Allows you to publish your data products - such as R Shiny apps - securely to your customers. Github: The central store of your work (your code). Allows you to share your code with others, and collaborate on code projects together. 1.1.2  High level diagram of the platform: 1.2 Why should I use the Analytical Platform? The Platform provides a number of advantages over existing analytical infrastructure: It provides access to the latest versions of modern analytical software, such as R Studio, It provides more powerful computational resources (12Gb RAM and fast CPUs) than DOM1 machines. It can be accessed from multiple computer systems - DOM1, Quantum (HMPPS’s system), and MacBooks. It allows analysts to securely deploy data products such as R Shiny applications and web sites, including web-base data visualisations. The platform is hosted in the cloud, which means it is scalable and easy to access remotely. Data storage is unlimited, and computational resource can be scaled to demand. 1.3 FAQ: How do I? This section covers common tasks you may want to complete on the platform. If we’ve missed something, let us know. Get access to the platform See Getting Started. Share data or code with a team If you haven’t set up a team yet, see User Administration. If you’ve got a team but want to upload data see Uploading data to S3. If you want to share code see guidance on Github. Upload and work with data If the data isn’t shared, and is less than 100 MB, you can upload it directly to R Studio. See ‘uploading files’ here. If you want to share the data, or if it’s more than 100 MB, you’ll need to set up a team, then upload data (see Uploading data to S3 ). To import data from S3 into R for analysis, see Importing data from S3 into R. Make an interactive dashboard and deploy it securely See Deploying a Shiny App. 1.4 Contacting us For quick support, contact us on the #analytical_platform Slack channel. Alternatively, contact us by email "],
["getting-started.html", "Part 2 Getting Started 2.1 Getting an account 2.2 Accessing the platform 2.3 Configuring Git and Github for use on the Analytical Platform 2.4 Guidance on writing code 2.5 Training Resources", " Part 2 Getting Started 2.1 Getting an account 2.1.1 Sign up to Github You need a Github account to be able to access the platform. If you do not already have an account, head to https://github.com/ and sign up. When signing up, use all the default options. We recommend new users use their @justice email address. If you already have a personal Github account, you may also just use that. For more information about why we’ve made Github a core part of the platform, see here. 2.1.2 Enable two-factor authentication on your Github account Once you’ve signed to Github, you must enable two factor authentication on your Github account to enhance security. You can do this in your Github settings page. You are given the option of doing this using SMS, or an authentication app such as Authy or Google Authenticator . Choose whichever you prefer. Save a copy of your recovery codes, for example by emailing them to your secure government email address. For step-by-step instructions, see the Github guidance for authentication apps or SMS authentication. 2.1.3 Email us your Github username Once you’ve got a Github account setup, email your github username to Leanne Mills (or Robin Linacre if she’s out of office) who will invite you to the private MoJ Analytical Services organisation. This invitation will trigger an email notification, or you can accept the invitation by visiting MoJ Analytical Services organisation. Once you’ve accpted the invitation, you’ve now completed all the security prerequisites, and you’re ready to access the platform. 2.1.4 Read the Security Operating Procedure Before you start using the platform, please read the Acceptable use policy. 2.2 Accessing the platform Click here to access the platform. When you first access your platform account, you will be asked to set up additional two factor authentication for the platform itself. You must do this using an authentication app on your personal or work phone (such as Authy or Google Authenticator). There is no SMS option. For troubleshooting 2FA issues, please see this section of the user guidance. 2.3 Configuring Git and Github for use on the Analytical Platform Github enables you to collaborate with colleagues on code and share you work with them. It puts your code in a centralised, searchable place. It also enables you to version control your work. If you are new to Git and Github, it is worth clarifying the difference between Git and Github. Git is the software that looks after the version control of code, whereas Github is the website on which you publish and share your version controlled code. In practice this means you use Git to track versions of your code, and then submit those changes to Github. This guide runs through how to set up connectivity between your Analytical Platform account and Github. This is a one-time set up procedure; you only need to do this once, when you first use the platform. This page covers only the initial setup. For guidance on how to use Git to sync your work with Github, please see the information here or here. We have also published a suggested working pattern here. You can find more detailed notes about setting up Git with R Studio here and here 2.3.1 Instructions The overview is as follows: Create an ‘SSH key’ within your platform R Studio. This is an unique code that is stored in your account. Having the key means you will not need to enter your password when interacting with Github. Register the key with Github. Configure git to use your username and email address. 2.3.1.1 Step 1 - create an SSH key You can create your SSH key within the platform: Tools -&gt; Global options -&gt; Git/SVN -&gt; Create RSA key... You will be presented with dialog showing your key fingerprint, amongst other details. You do not need this information, therefore close the window: For the next step, you’ll need to copy and paste your SSH public key. You can copy this to the clipboard using the following dialogues: You can find more information about SSH keys in this guidance. 2.3.1.2 Step 2: Register the key with Github. The next step is to register your SSH public key with Github, using the interface on www.github.com. This guidance assumes you have copied your public key to your computer’s clipboard in the previous step. First, navigate to the Github homepage. If you are not logged in already, you will need to log in. Access your settings from the menu that appears when you click on your profile picture in the top right. Once in settings, access your SSH and GPG keys. Here’s a direct link. Click on New SSH key. Paste your key into the dialogue that pops up and click Add SSH key. You can choose any name you like for the ‘title’ of the key. The link with Github and the Analytical Platform is now established. You can now return to the analytical platform. Configure your Git name and email address within the analytical platform. To start syncing your work with Github, Git needs to know a bit more about you. Within the platform, access the shell using Tools -&gt; Shell... Then, you need to type the following commands (substitute your name and email): git config --global user.name &#39;Your Name&#39; git config --global user.email &#39;your@email.com&#39; You’re now ready to start using Github! 2.3.2 Using Git with the Analytical Platform We have written an introductory guide to using Git which you can access here. 2.4 Guidance on writing code Please read the coding standards. 2.5 Training Resources The data science team maintain a list of R training here. "],
["working-with-big-datasets-and-sharing-them-accessing-data-in-amazon-s3.html", "Part 3 Working with big datasets and sharing them: Accessing data in Amazon S3 3.1 Importing data from S3 into R 3.2 Uploading data to S3", " Part 3 Working with big datasets and sharing them: Accessing data in Amazon S3 Amazon S3 is used as the primary storage area for large data files. In contrast to data in your Platform’s home directory, data in S3 can be accessed by multiple Platform users. You will only be able to access S3 buckets (folders) that you have been granted access to (see User Administration). 3.1 Importing data from S3 into R There are currently two methods of browsing and importing data held in S3 into RStudio. 3.1.1 User Interface We have developed a user interface that allows you to search and browse the files that you have been given access to. You can access this interface by typing the following command into your R Studio console: s3browser::file_explorer_s3() See the documentation for further details. 3.1.2 Command line tool We have also developed a command line tool that provides you with some helper function. This enables you to do things like write s3tools::s3_path_to_full_df(&quot;alpha-everyone/CW iris.xlsx&quot;) to read directly from S3 into a data frame in R. See the documentation for further details. 3.2 Uploading data to S3 3.2.1 Where data is stored Data in s3 is stored in ‘buckets’, which are conceptually very similar to folders. An S3 bucket is automatically created for every team that’s created in Github; for how to create and manage teams see User Administration. By default, all members of a Github team have read and write access to their corresponding bucket. 3.2.2 Uploading data To access the buckets you need to visit the Amazon management console with the following link: https://alpha-analytics-moj.eu.auth0.com/samlp/NpfImg4P3ynU6HFx7ivYmqUZWQHfwi3Y (if you regularly upload data it may be worth bookmarking this link). Authentication is managed by GitHub, so if this is the first time you are connecting to the Amazon S3 Management console you may have to approve it. You’ll be able to see all buckets, including those you do not have access to. You can only see the contents of buckets to which you have access. To upload data, find the bucket you want to upload data to. Within the bucket you can create folders and upload files by following the on screen instructions. When uploading files you will be prompted to set the settings for that file. If this happens, the default settings are okay. 3.2.2.1 Step-by-step instructions Use the following link to login Select the S3 service Select the bucket you wish to upload data to (the bucket will have the same name as the team, but spaces are replaced with - and all letters are lower case, so Test Team will have a bucket called test-team). While in alpha all buckets will also have the alpha prefix. You’ll notice two buckets are created; use the one prefixed alpha- and ignore the one prefixed dev-. The easiest way is to use the search: Use the interface to create folders or upload files. Note: The default settings are fine. 3.2.2.2 Manipulating data You can also move, rename and delete data using the S3 management console. Select the files by checking the text box, use the More button so see the options. "],
["using-github-with-r-studio.html", "Part 4 Using Github with R Studio 4.1 Syncing you R Studio work with Github 4.2 Working on a branch. 4.3 Git training Resources 4.4 Other tips and tricks [Work in progress!]:", " Part 4 Using Github with R Studio Github enables you to collaborate with colleagues on code and share you work with them. It puts your code in a centralised, searchable place. It enables easier and more robust approaches to quality assurance, and it enables you to version control your work. This guide provides a step-by-step guide of how to create a project and sync your work with Github. You can find more in-depth Git training resources here Note: If any of the animated gifs below do not display correctly, try a different web browser e.g. Microsoft Edge, which is installed on your DOM1 machine. 4.1 Syncing you R Studio work with Github 4.1.1 Step 1 - Create a new project (‘repo’) in the moj-analytical-services Github page This is conceptually similar to setting up a folder on the DOM1 shared drive to save your work, and share it with others. The files in this Github repo represent the definitive version of the project. Everyone who works on the project makes contributions to this definitive version from their personal versions. Note that if you want to contribute to an existing project, you can skip this step. To begin, navigate to www.github.com and make sure you’re logged in. Once logged in, go to the MoJ Analytical Services homepage at https://github.com/moj-analytical-services/ Then follow the steps in this gif to create a new repository. Notes: Make sure that the repository is set to ‘private’. This is the default setting. If you change this setting to ‘public’, your code will be available on the open internet. Make sure the owner is set to ‘moj-analytical-services’. This is the default setting, so long as you have clicked on ‘New’ from the https://github.com/moj-analytical-services homepage. 4.1.2 Step 2: Navigate to your platform R Studio and make a copy of the Github project in your R Studio In this step, we create a copy of the definitive github.com project in your personal R Studio workspace. This means you have a version of the project which you can work on and change. Follow the steps in this gif: Notes: When you copy the link to the repo from Github, ensure you use the ssh link, which start git@github.com as opposed to the https one, which start https://github.com/ 4.1.3 Step 3: Edit your files, track them using Git, and sync (‘push’) changes to Github Edit your files as usual using R Studio. Once you’re happy with your changes, Git enables you to create a ‘commit’. Each git commit creates a snapshot of your personal files on the Platform. You can can always undo changes to your work by reverting back to any of the snapshots. This ‘snapshotting’ ability is why git is a ‘verson control’ system. In the following gif, we demonstrate changing a single file, staging the changes, and committing them. In reality, each commit would typically include changes to a number of different files, rather than the single file shown in the gif. Notes: ‘commiting’ does not sync your changes with github.com. It just creates a snapshot of your personal files in your R Studio environment. Git will only become aware of changes you’ve made after you’ve saved the file as shown in the gif. Unsaved changes are signified when the filename in the code editior tab is red with an asterix. ### Step 4: Sync (‘push’) your work with github.com In R Studio, click the ‘Push’ button (the green up arrow). This will send any change you have committed to the definitive version of the project on Github. You can then navigate to the project on Github in your web browser and you should see the changes. Notes: After pushing, make sure you refresh the GitHub page in your web browser to see changes. That’s it! If you’re working on a personal project, and are not collaborating with others, those three basic steps will allow you to apply version control to your work with Github 4.1.4 Using the shell If you are more comfortable using the shell (terminal) you can do steps 3 and 4 using the following git commands: * Select the files you want to commit (known as staging): git add &lt;filename1&gt; &lt;filename2&gt; * Commit the files you have staged: git commit. After calling this command a popup will ask you to write in a commit message. After doing so press enter. * Finally push your changes to GitHub: git push origin &lt;branch_name&gt;. Most likely your branch name will be master which is the default. So your code would be git push origin master. 4.2 Working on a branch. One of the most useful aspects of git is ‘branching’. This involves a few extra steps, but it enables some really important benefits: Allows you to separate out work in progress from completed work. This means there is always a single ‘latest’ definitive working version of the code, that everyone agrees is the ‘master copy’. Enables you and collaborators to work on the same project and files concurrently, resolving conflicts if you edit the same parts of the same files. Enables you to coordinate work on several new features or bugs at once, keeping track of how the code has changed and why, and whether it’s been quality assured. Creates intutitive, tagged ‘undo points’ which allow you to revert back to previous version of the project e.g. we may wish to revert to the exact code that was tagged ‘model run 2015Q1’. We therefore highly recommend using branches. (Up until now, we’ve been working on a single branch called ‘master’.) 4.2.1 Step 1 (optional): Create an Issue in github that describes the piece of work you’re about to do (the purpose of the branch) Github ‘issues’ are a central place to maintain a ‘to do’ list for a project, and to discuss them with your team. ‘Issues’ can be bug fixes (such as ‘fix divide by zero errors in output tables’), or features (e.g. ‘add a percentage change column to output table’), or anything else you want. By using issues, you can keep track of who is working on what. If you use issues, you automatically preserve a record of why changes were made to code. So you can see when a line of code was last changed, and which issue it related to, and who wrote it. 4.2.2 Step 2: Create a new branch in R Studio and tell Github about its existence Create a branch with a name of your choosing. The branch is essentially a label for the segment of work you’re doing. If you’re working on an issue, it often makes sense to name the branch after the issue. To create a branch, you need to enter the following two commands into the shell: checkout -b my_branch_name. Substitute my_branch_name for a name of your choosing. This command simultaneously creates the branch and switches to it, so you are immediately working on it. git push -u origin my_branch_name. This tells github.com about the existence of the new branch. 4.2.3 Step 3: Make some changes to address the Github issue, and push (sync) them with Github Make changes to the code, commit them, and push them to Github. 4.2.4 Step 4: View changes on Github and create pull request You can now view the changes in Github. Github recognises that you’ve synced some code on a branch, and asks you whether you want to merge these changes onto the main ‘master’ branch. You merge the changes using something called a ‘pull request’. A ‘pull request’ is a set of suggested changes to your project. You can merge these changes in yourself, or you can ask another collaborator to review the changes. One way of using this process is for quality assurance. For instance, a team may agree that each pull request must be reviewed by a second team member before it is merged. The code on the main ‘master’ branch is then considered to be quality assured at all times. Pull requests also allow you and others working on the project to leave comments and feedback about the code. You can also leave comments that reference issues on the issue log (by writing # followed by the issue number). For example you might comment saying “This pull request now fixes issue #102 and completes task #103”. 4.2.5 Step 5: Sync the changes you made on github.com with your local platform When you merged the pull request, you made changes to your files on Github. Your personal version of the project in your R Studio hasn’t changed, and is unaware of these changes. The final step is therefore to switch back to the ‘master’ branch in R Studio, and ‘Pull’ the code. ‘Pulling’ makes R Studio check for changes on Github, and update your local files to incorporate any changes. 4.3 Git training Resources If you are new to git and you want to learn more, we recommend that you complete the basic tutorial available here. The slides from from the ASD git training are available here (dom1 access only) Using Github with R Introductory interactive tutorial. Quickstart guide and cheatsheet here and in pdf format here. More in depth materials: Learn Git branching Git from the inside out 4.4 Other tips and tricks [Work in progress!]: 4.4.1 Search the code in MoJ Analytical Services to see who else has used a package. 4.4.2 Hyperlink to a specific line of code in your project 4.4.3 Make your project available to people on different teams 4.4.4 Assign a reviewer to a pull request, and leave comments. 4.4.5 View how files have changed on the platform and on "],
["deploying-a-shiny-app.html", "Part 5 Deploying a Shiny App 5.1 Step-by-step guide to deploying an app 5.2 Accessing the app 5.3 Access Levels 5.4 Advanced deployment", " Part 5 Deploying a Shiny App The following steps to deploy a Shiny app are as follows: Copy the template project within Github to a new repository, with a name of your choice. In R Studio, start a new project from version control (file -&gt; new project -&gt; version control -&gt; git). TODO: Remember to make sure the template has a Rproj that enables packrat Work on your Shiny app, using the template ui.R and server.R files. Ensure that your package dependencies are snapshotted using packrat::snapshot() When you’re ready to share it, access the Services control panel, find your app, and click ‘Build now’. Once deployed, grant users access to the app by inserting their names into the Grant user access control panel. Step-by-step instructions are below. For advanced users, the guidance here discusses customisability and options for deployment. Refer to this guidance if you are already familiar with git, packrat etc. 5.1 Step-by-step guide to deploying an app 5.1.1 Copy the template project into a new Github repository Begin by making a copy of the R Shiny template project on Github: https://github.com/new/import. Enter https://github.com/moj-analytical-services/rshiny-template in the input box entitled ‘your old repository’s clone URL:’ Ensure the ‘owner’ of the new repository is ‘moj-analytical-services’ and choose a name for your repository: Make sure the repo is ‘private’ (this should be the default value): Click ‘Begin import’ 5.1.2 In R Studio in the platform, create a new project from your new Github repository In R Studio, navigate through the following menus: File -&gt; New project -&gt; Version control -&gt; Git In ‘Repository URL’, enter the URL of the repository you just created. This needs to be the SSH URL (starting with git@github), NOT the HTTPS url (which starts with https). Therefore, it is in the following format: git@github.com:moj-analytical-services/your_name_goes_here.git R Studio will create a new project folder with all the template files in. You can now start building your Shiny app by editing server.R and ui.R files. 5.1.2.1 Further notes if you’re having trouble finding your new repo’s url If you navigate to your new repository’s home page (which will have a url in the form https://github.com/moj-analytical-services/your_name_goes_here), you can use the following buttons to access this url (make sure you click the ‘ssh’ button): 5.1.3 Work on your app You can now work on your Shiny app in R Studio as normal. As you work, commit your changes to Github using your chosen Github workflow. 5.1.4 Snapshot dependencies using packrat Your Shiny app will have dependencies on various third-party R packages (e.g. dplyr). These packages change through time, and sometimes these changes are not backwards compatible. When we deploy your Shiny app, it is therefore essential to include a manifest of all of the package dependencies and their specific versions. The R packagepackrat automates this process. Before deploying your app, you need to call packrat::snapshot() to automatically create this manifest. You may want to call packrat::clean() to remove any dependencies that are no longer in use. This creates a file called packrat/packrat.lock. You need to ensure you have committed this to the Github repository prior to deployment. 5.1.5 Scan organisation and deploy The platform automatically scans git repositories in the moj-analytical-services Github organisation to find repos that are ready to deploy. It does this by checking whether repositories contains two ‘magic’ files that control deployment: Jenkinsfile and Dockerfile. To deploy your app, go here. You will see a list of apps that have been detected. Find yours and click on the link with its name (if you’re app isnt listed then click “Scan Organisation Now” on the left hand menu and wait for the scan to complete. This step may take a few minutes.) Then click on the branch you wish to deploy (this will usually be ‘master’) Click ‘Build’. If this is the first time you’ve deployed the webpage it will be setup as a private page (only accessable to users with a given email). If you wish to grant access based on IP or make the website public you’ll need to build again: For the second build you be asked whether email authentication should be enabled (where you grant users access using their email address or if access is restricted based on network). For a ellaboration on this see Access levels. In the example below, I grant unrestricted access to the app. 5.1.6 Grant secure access to the app If you deployed with authentication enabled users are granted access to the app using a list of email addresses separated with a space, comma or semicolon. To grant access, complete the form here, and press ‘Build’. For example, your form might look like this: NOTE: Any characters which are not alphanumeric or dashes are converted into dashes. 5.2 Accessing the app Only users who you have granted access to will be able to access your app - the url for the app will be the respository-name followed by apps.alpha.mojanalytics.xyz. So for the example project above “test-shiny-project”, the deployment url will be https://test-shiny-project.apps.alpha.mojanalytics.xyz. Note that characters that are not compatible with website URLs are converted. So, repositories with underscores in their name (e.g. repository_name.apps...) will be converted to dashes for the URL (e.g. repository_name.apps...). Users will be prompted to enter their email and, if they are on the approved list, be sent a access link to view the app. 5.3 Access Levels When deploying a static website you’ll be asked for IP restrictions and whether authentication is required. IP restrictions restrict access the the static website based on the users network address. This can be useful if you want to make a site accessable to the organisation, without having to grant access on an email-by-email basis. The available levels are: DOM1 (excluding guest WiFi users but including those using AnyConnect) DOM1 and Quantum DOM1, Quantum and 102PF WiFi (including guest WiFi users) DOM1, Quantum, 102PF WiFi and Clive House WiFi (including guest WiFi users) Any location (this is a public website) The authentication tickbox determines whether or not users will have to be granted access via their email address. If you wish to enable this option visit the grant user access control panel, where you can enter a list of emails. For more info see the secure access documentation. 5.4 Advanced deployment This section contains guidance for advanced users on app deployment. 5.4.1 What is run when I deploy a Shiny app? When you deploy an app, the R Shiny server runs shiny::runApp() within the project. This is equivalent to when you press ‘run’ in a R Shiny project within R Studio. To understand how you can use this to deploy apps of different types, we can refer to the runApp docs. Specifically, the ‘arguments’ section is useful: Arguments appDir The application to run. Should be one of the following: A directory containing server.R, plus, either ui.R or a www directory that contains the file index.html. A directory containing app.R. An .R file containing a Shiny application, ending with an expression that produces a Shiny app object. A list with ui and server components. A Shiny app object created by shinyApp. One of those options is A directory containing app.R., which should contain: An .R file containing a Shiny application, ending with an expression that produces a Shiny app object.. This gives the developer a wider range of options of how to deploy a Shiny app, and makes it possible to deploy shiny apps that are bundled into pre-existing packages e.g. see here. 5.4.2 Can I change my build? Yes - if you know Docker, you are welcome to change the Dockerfile. 5.4.3 How can I troubleshoot problems? To view the logs, see the Kibana dashboard. Here are some tips to reduce problems: Test early and often by deploying work in progress rather that building an entire app and testing Explicitly reference all packages (e.g. shiny::hr() rather than hr(). This is particularly important if you’re using loads of packages. If you’re having problems, delete everything in packrat/ and re-run packrat::init(). The most useful logs which Shiny produces are in Kibana. You can also access them by locally building Docker on your mac, but it’s a bit of a faff. Try to minimise the number of packages you’re using, each additional package is another source of problems When testing, clone the repo to another folder and test the cloned code. This guarantees that the code you’re testing is the same code which will be deployed on the platform If you’re still having problems, you can deploy the app locally using Docker. 5.4.4 Troubleshooting using Docker (installed locally on a Macbook) Docker enables us to fully specify a computing environment (an operating system and the software installed on that system). This allows us to test and troubleshoot our Shiny app in Docker on our Macbooks. If it runs in Docker on the Macbook, it will also run on the platform, because Docker guarantees the computing environments will be the same. This guarantee only applies if we build the Docker image from exactly the same code (the same Shiny code, and the same Dockerfile). When we deploy a Shiny app on the platform, the following steps take place: The platform clones your git repository The platform runs docker build on the resultant code The platform runs resultant the docker image. To test your Shiny app in Docker on your Macbook, we highly recommend that you git clone your repository to a new folder on your macbook. This guarantees that the code used to build your Docker image is exactly the same code that is checked into github. If you build from your local working copy, your build may rely on local modifications to files which you haven’t committed to github, and therefore may differ from what is built on the platform. The following provides more detailed instructions. First cd into the directory containing the Dockerfile. Then run: docker build . -t your_name_here (your_name_here is the tag you want to give to the image) By building the image, it will test the installation of the packrat dependencies and package your shiny app into a Linux environment identical to what’s on the platform. Remember to refresh Docker if you are re-building a previously built app in the directory (the previous build will show when you view the app otherwise). Run the Shiny server in a linux container with docker run -p 80:80 your_name_here You can then go to http://127.0.0.1:80 to see if the app is working. If it is not, you can investigate what’s going on in the server using: docker run -it -p 80:80 your_name_here bash Note this will start a bash session in the container, but it will not start the shiny server. i.e. it starts bash instead of running /bin/shiny-server.sh. We can then configure logging in the container, before starting the shiny server as follows: Install the nano text editor: apt-get update apt-get install nano Then edit the config file at nano /etc/shiny-server/shiny-server.conf to add the following two lines at the beginning: access_log /var/log/shiny-server/access.log tiny; preserve_logs true; Save by pressing [CTRL]+[O] and then exit with [CTRL]+[X]. Finally change the log level to be more verbose and start the shiny server: export SHINY_LOG_LEVEL=TRACE /bin/shiny-server.sh For further details see the rshiny-server documetation Now we need another terminal window, to get back into the docker container docker ps to find the name of the container and then docker exec -it container_name bash Logs are then written to cd /var/log/shiny-server/ 5.4.5 If all else fails… Sometimes, the following steps can resolve problems with packrat.lock: Delete the entire packrat directory Comment out all code in the project Enable packrat with packrat::init() Freeze packrat dependencies with packrat::snapshot() Uncomment all code in project, and install dependencies one at a time using install.packages() packrat::snapshot() again Try redeploying 5.4.6 Some problems we’ve encountered and their solutions 5.4.6.1 Shiny app deploys successfully, but ‘application failed to start’ error occurs Sometimes, your Shiny app deploys successfully but you get the following error: An error has occurred The application failed to start. The application exited during initialization. This is a generic error which means that there is an error in your R code or there are missing packages (e.g. your code includes references to packages which aren’t in your packrat.lock. Try the following two steps: Make sure you’ve run packrat::snapshot() and committed the resultant packrat.lock file to Github We’ve encountered issues due to ambiguous references to function calls. Make sure that function calls include the full reference (e.g. shiny::hr() rather than just hr()). For an example of this type of problems, see here "],
["deploying-a-static-web-app.html", "Part 6 Deploying a Static Web App 6.1 Step-by-step guide to depolying an static web app 6.2 Accessing the app 6.3 Access Levels 6.4 Advanced deployment", " Part 6 Deploying a Static Web App The following steps to deploy a Shiny app are as follows: Copy the template project within Github to a new repository, with a name of your choice. In R Studio, start a new project from version control (file -&gt; new project -&gt; version control -&gt; git). TODO: Remember to make sure the template has a Rproj that enables packrat Work on your static website - the exposed content will be in the www/ directory and www/index.html will be the landing page. When you’re ready to share it, access the services control panel, find your app, and click ‘Build now’. This will prepare your site for deployment. Once the first deployment has completed, revisit the services control panel and deploy again. This time you will be prompted to select permission levels for the site (i.e. whether it should be available for DOM1, Quantum, or external). 6.1 Step-by-step guide to depolying an static web app 6.1.1 Copy the template project into a new Github repository Begin by making a copy of the R Shiny template project on Github: https://github.com/new/import Enter https://github.com/moj-analytical-services/webapp-template in the input box entitled ‘your old repository’s clone URL:’ Ensure the ‘owner’ of the new repository is ‘moj-analytical-services’ and choose a name for your repository: Make sure the repo is ‘private’ (this should be the default value): Click ‘Begin import’ 6.1.2 In your chosen development enviroment, clone the git repository You can find the clone link on the Github repository. To download a copy to start editing on your local machine, you need to ‘clone’ the repositry. If you’re using a shell: git clone git@github.com:moj-analytical-services/YOUR-REPO-NAME.git 6.1.2.1 Further notes if you’re having trouble finding your new repo’s url If you navigate to your new repository’s home page (which will have a url in the form https://github.com/moj-analytical-services/your_name_goes_here), you can use the following buttons to access this url (make sure you click the ‘ssh’ button): 6.1.3 Work on your web app Work on your web app using your chosen development enviroment. As you work, commit your changes to Github using your chosen Github workflow. 6.1.4 Scan organisation and deploy The platform automatically scans git repositories in the moj-analytical-services Github organisation to find repos that are ready to deploy. It does this by checking whether repositories contains two ‘magic’ files that control deployment: Jenkinsfile and Dockerfile. To deploy your app, go here. You will see a list of apps that have been detected. Find yours and click on the link with its name (if you’re app isnt listed then click “Scan Organisation Now” on the left hand menu and wait for the scan to complete. This step may take a few minutes.) Then click on the branch you wish to deploy (this will usually be ‘master’) Click ‘Build’. If this is the first time you’ve deployed the webpage it will be setup as a private page (only accessable to users with a given email). If you wish to grant access based on IP or make the website public you’ll need to build again: For the second build you be asked whether email authentication should be enabled (where you grant users access using their email address or if access is restricted based on network). For a ellaboration on this see Access levels. In the example below, I grant unrestricted access to the app. 6.2 Accessing the app Depending on the settings you selected, the website will either be available directly or authenticated via email. The URL for the app will be the respository-name followed by apps.alpha.mojanalytics.xyz. So for the example project above “static-web-deploy”, the deployment URL will be https://static-web-deploy.apps.alpha.mojanalytics.xyz. Note that characters that are not compatible with website URLs are converted. So, repositories with underscores in their name (e.g. repository_name.apps...) will be converted to dashes for the URL (e.g. repository_name.apps...). 6.3 Access Levels When deploying a static website you’ll be asked for IP restrictions and whether authentication is required. IP restrictions restrict access the the static website based on the users network address. This can be useful if you want to make a site accessable to the organisation, without having to grant access on an email-by-email basis. The available levels are: DOM1 (excluding guest WiFi users but including those using AnyConnect) DOM1 and Quantum DOM1, Quantum and 102PF WiFi (including guest WiFi users) DOM1, Quantum, 102PF WiFi and Clive House WiFi (including guest WiFi users) Any location (this is a public website) The authentication tickbox determines whether or not users will have to be granted access via their email address. If you wish to enable this option visit the grant user access control panel, where you can enter a list of emails. For more info see the secure access documentation. 6.4 Advanced deployment This section contains guidance for advanced users on app deployment. 6.4.1 Can I change my build? Yes - if you know Docker, you are welcome to change the Dockerfile. "],
["common-errors-and-solutions.html", "Part 7 Common Errors and Solutions 7.1 Failed to lock directory 7.2 rsession-username ERROR session hadabend 7.3 Status Code 502 error message 7.4 Unable to access data using aws.s3 package. 7.5 s3tools::s3_path_to_full_df() fails on Excel file 7.6 Two Factor Authentication problems 7.7 I’m having problems deploying a Shiny app", " Part 7 Common Errors and Solutions 7.1 Failed to lock directory This error is typically encountered after a failed package install. Error ERROR: failed to lock directory ‘/home/robinl/R/library’ for modifying Try removing ‘/home/robinl/R/library/00LOCK-readr’ Solution Run the following: install.packages(&#39;pacman&#39;) pacman::p_unlock() If that does not work, or if you have trouble installing the pacman package, try the following: Go to Tools -&gt; Shell and type: rm -rf /home/robinl/R/library/00LOCK-readr See here for more details. Be careful with the rm command! 7.2 rsession-username ERROR session hadabend Errors like the following can typically be ignored: [rsession-aidanmews] ERROR session hadabend; LOGGED FROM: rstudio::core::Error {anonymous}::rInit(const rstudio::r::session::RInitInfo&amp;) /home/ubuntu/rstudio/src/cpp/session/SessionMain.cpp:1934 They seem to occur when R Studio has been unable to restore your session following a crash. Note the items in your R environment will no longer be there following a crash, and you’ll need to re-run your scripts to bring your data back into memory. Crashes often occur when you run out of memory. For now, you can use pryr to track your memory usage - see here. We are working on giving users greater visibility of their memory usage. 7.3 Status Code 502 error message R Studio Server is single-cpu (single thread), which means it can’t ‘do two things at once’. If you ask it to, sometimes one of the operations will timeout. The ‘Status code 502’ message is basically a timeout message. Usually this doesn’t cause anything to crash. You just need to wait for the currently-running code to finish executing and try again. One example of when this can happen is if you attempt to save a file whilst a long-running script is running. R Studio has to wait until the script has finished running to attempt to save the file. However, sometimes the wait is too long, causing a timeout. In this case, you just need to wait for the code to finish running, and then press save again. 7.4 Unable to access data using aws.s3 package. Unfortuntely aws.s3 does not support the granular file access permission model we are using on the platform. Specifically, it is unable to automatically provide the user with the right file access credentials. We provide s3tools as a solution to this problem, which manages your credentials for you. We recommend that, where possible, users should use s3tools. Where this is not possible, include a call to s3tools::get_credentials() prior to making the call to aws.s3, and this will guarantee that fresh credentials are generated before your call to aws.s3 7.5 s3tools::s3_path_to_full_df() fails on Excel file s3tools::s3_path_to_full_df attempts to read in data from various filetypes, including Excel, but this sometimes fails. If it does, you have two options: 7.5.0.1 Option 1: Use s3tools::read_using() This allows you to specify what function you want to use to attempt to read the file. So, for example you can do: s3tools::read_using(openxlsx::readWorkbook, path = &quot;alpha-everyone/my_excel.xlsx&quot;) to attempt to read the file alpha-everyone/my_excel.xlsx using openxlsx::readWorkbook 7.5.0.2 Option 2: Save the file to your project directory and load it from there, rather than from S3 s3tools::get_credentials() aws.s3::save_object(&quot;my_excel.xlsx&quot;, &quot;alpha-everyone&quot;, &quot;file_name_to_save_to_in_home_directory.xlsx&quot;) and then read it in using e.g. openxlsx::readWorkbook(&quot;file_name_to_save_to_in_home_directory.xlsx&quot;) Note, it’s best to avoid using aws.s3 directly, see here 7.6 Two Factor Authentication problems Two factor authentication is critical to the security of the platform. We have opted to use smartphone based 2FA apps due to the expense of giving out hardware tokens like the RSA device you use to log in to DOM1. Note that there are two layers of two factor authentication (2FA) in action on the platform: Your Github account must have 2FA enabled. When you log in to Github, your session will stay active for a month before you need to re-enter your 2FA code. Your Github username identifies you to the platform, and we use this identity to control access to data and other resources once you’ve logged into the platform. You therefore must be logged into Github to use the platform. You Analytical Platform account has a separate 2FA step. You will be prompted to set this up the first time you access the platform. This code must be entered once a day. This security step lets you log into the platform and use it. Usually, when you log into the platform, you will be prompted to enter your platform 2FA, but you will not need to enter your Github 2FA because this is remembered for a month. However, if you have not logged into the platform for more than a month, you will first have to login to Github (and enter your Github 2FA code), and you will then also be prompted to enter your platform 2FA code. 7.6.1 I’ve lost my platform 2FA If you’ve lost your platform 2FA code because e.g. you’ve broken or lost your phone, please contact the Analytical Platform team and we will reset it for you. 7.6.2 I have entered my 2FA code, but the platform will not accept it Smartphone based 2FA apps require the phone’s clock (the time) to be up to date. If your phone’s clock is out of sync by more than 30 seconds or so, this can cause the 2FA codes to be out of sync. Most phones syncronise their time with the network provider, so this is not a problem. If your time is out of sync, you need to navigate to your clock settings in your phone, and enable the option to sync the time. See e.g. here 7.7 I’m having problems deploying a Shiny app For help resolving deployment problems, see the advanced deployment section of the docs. "],
["user-administration.html", "Part 8 User Administration 8.1 Teams and data access groups", " Part 8 User Administration 8.1 Teams and data access groups Users, teams and data access are all managed from Github Teams. Every team is automatically granted an S3 Bucket (a shared storage area). Teams and the associated S3 Bucket can be used in two ways: As as a shared area for a team. As “data access groups” where each member of the Github “team” is cleared to access a given dataset. For how to access buckets from within R see here. 8.1.1 Team creation See Githubs Guidence for a step-by-step guide on how to setup teams. A list of teams can be found here. 8.1.1.1 Team name When creating a team, make sure that the name of the team is clear, concise, and unique. Particularly as this will be the name of the folder where the associated data will be stored. Team names may contain spaces, but we recommend that you_use_underscores or you-use-dashes instead. Teams can either be teams or data access groups. If a bucket contains a core data set then it should be uploaded to a data access group and not a team shared storage area. In practise, individuals will probably be members of multiple teams and data access groups. Importantly, data access groups should be prefixed DAG_team_name. 8.1.1.2 Team visability Teams can be visable or secret. Visible teams can be viewed by all members of the organisation (those who are on Github but not on your team), whereas secret teams can only be viewed by members of that team. 8.1.1.3 Troubleshooting: I can’t create teams You will only be able to add team members that are part of the organisation. As part of the setup process users should already be added to the organisation. If they’re not then email Robin Linacre or Leanne Mills. 8.1.2 Adding or removing users from a team Step-by-step guidance on how to add or remove team members is available on Github. Note that when a user is added they are also authorised to access the data. Similarly, when they are removed, access to the data is revoked. 8.1.3 Team member permissions Members of a team can be Maintainers or Members. See the Github Guidance on how to set permissions for team members. Maintainers have the following additional permissions, and can be thought of as team administrators: Change the team’s name and description Change the team’s visibility Add organization members to the team Remove organization members from the team Promote an existing team member to team maintainer Remove the team’s access to repositories Reinstate a former organization member "],
["acceptable-use-policy-security-operating-procedures.html", "Part 9 Acceptable Use Policy (Security Operating Procedures) 9.1 General security guidance 9.2 Transferring and management of data 9.3 Guidance on the use of Github 9.4 Reporting security incidents", " Part 9 Acceptable Use Policy (Security Operating Procedures) You must not put any sensitive (OFFICIAL) data into the platform. Sensitive data is classified OFFICIAL or higher. If you really need to put this kind of data into the platform, either: get formal permission from Robin Linacre, or get in contact on the #analytical-platform channel on Slack. Remember that the platform is still in Beta. This means there is no guarantee of stability. Do not use the platform for time-critical tasks. Allow for the possibility of unannounced downtime, which could last up to a week. If you are responsible for a team, ensure that users have the correct permissions. 9.1 General security guidance Do not access the platform from a non-MoJ computer. For example, do not attempt access from a personally-owned computer. Choose a complex password for your Github account. A complex password cannot be guessed, and is created by following some simple rules and suggestions; see here You must not share your account or your login credentials with anyone else. 9.2 Transferring and management of data Transfer to the platform only the minimum possible datasets needed for your work. All data transfers should be made from a secure computer system. The system must be accredited to store OFFICIAL data, such as DOM1 or QUANTUM systems. Access to sensitive data should be provided on a ‘need to know’ basis. Use data access groups to control data access. 9.3 Guidance on the use of Github The advice in this document relates to private repositories which are part of the MoJ Analytical Services organisation only. Do not store OFFICIAL work in public repositories unless you are sure it is not sensitive and have prior permission from your line manager. 9.3.1 What can I use GitHub for? When you have approval, you may use GitHub to store your analytical code at the OFFICIAL level. This means that you can use Git for work where the code itself is sensitive, such as work on court or prison closures. You may also use GitHub to store project writeups. However, the write ups must not contain information or data which would violate the prohibitions on the use of GitHub set out below. 9.3.2 Prohibitions: What are the limits on GitHub use? In general, you must not use GitHub to store datasets. Specifically, you MUST NOT use GitHub for the following purposes: To store any large datasets classified at OFFICIAL or above. Our working definition is that a large dataset contains over 1,000 records. To store any data whatsoever (in code or in datasets) where individuals are potentially identifiable and the data is not already in the public domain. To store credentials such as usernames and passwords, or secrets such as database connection strings. 9.4 Reporting security incidents You must report actual, attempted or suspected breaches of security as soon as discovered to: OperationalSecurityTeam@justice.gsi.gov.uk "],
["annexes.html", "Part 10 Annexes 10.1 What are the benefits of Github and why do we recommend it? 10.2 Step by step guide to setup of Two Factor Authentication", " Part 10 Annexes 10.1 What are the benefits of Github and why do we recommend it? Github is a central place to store our analytical projects - particularly those which are built primarily in code. It provides a range of poweful tools and functionality which will help you manage your work. This is useful if you’re work on your own, but the benefits are greatest when you’re working in a team. Here are some of the things that Git offers: It provides a single, unambigous master version of a project. No more model_final.r, model_finalv2_final.r. etc. It enables you and collaborators to work on the same project and files concurrently, resolving conflicts if you edit the same parts of the same files, whilst keeping track of who made what edits and when. It enables work in progress to be shareed with team members, without compromising the master version. You never get confused between what’s not yet final, and what’s trusted, quality assured code. The work in progress can be seemlessly merged into the master version when it’s ready. It provides a history of all previous versions of the projects, which can be meaningfully tagged, and reverted to (undo points). e.g. we may wish to revert to the exact code that was tagged ‘model run 2015Q1’. It provides extremely powerful search. The ability to search all code written by Ministry of Justice analysts in milliseconds. Or all code written by anyone, for that matter. It enables an easier, more robust, more enjoyable approach to quality assurance. In particular, it offers the potential to continuously quality assure a project as it’s built, rather than QA being an activity that’s only done once the work is complete. For example, all additions to the codebase can be reviewed and accepted by a peer before being integrated into the master version. It includes productivity tools like Github issues (essentially a tagged to do list), and a trello style workflow (Github projects), with automation. The to do list is automatically linked to the implementation - e.g. The issue of ‘fix number formatting’ is automatically linked to the specific changes in the code that fixed the number formatting. Git stores a huge amount of meta data about why changes were made and by whom. This dramatically reduces the danger of code becoming a ‘black box’. It makes it much easier to build reusable components, and make parts of our code open source (available to the public). For example, we use R code written by statisticians around the world that’s been put on Github, and we know that people across government have been using some of our R code. We can collaborate easily with other government deparments and anyone else for that matter. It makes it easier to ask for help with your work, particularly with colleagues who are working remotely. You can hyperlink and comment on specific lines of code. You can write rich, searchable documentation - e.g. this user guide is hosted on Github! 10.2 Step by step guide to setup of Two Factor Authentication Two factor authentication (2FA) is critical to the security of the platform. We have opted to use smartphone based 2FA apps due to the expense of giving out hardware tokens like the RSA device you use to log in to DOM1. Note that there are two layers of two factor authentication (2FA) in action on the platform: Github Account 2FA Your Github account must have 2FA enabled. When you log in to Github, your session will stay active for a month before you need to re-enter your 2FA code. Your Github username identifies you to the platform, and we use this identity to control access to data and other resources once you’ve logged into the platform. You therefore must be logged into Github to use the platform. Analytical Platform 2FA You Analytical Platform account has a separate 2FA step. You will be prompted to set this up the first time you access the platform. This code must be entered once a day. This security step lets you log into the platform and use it. Usually, when you log into the platform, you will be prompted to enter your platform 2FA, but you will not need to enter your Github 2FA because this is remembered for a month. However, if you have not logged into the platform for more than a month, you will first have to login to Github (and enter your Github 2FA code), and you will then also be prompted to enter your platform 2FA code. 10.2.1 Step by step - logging into the platform for the first time The first time you log into the Analytical Platform, you will be asked to set up 2FA. Your welcome email will direct you to the platform Control Panel. 10.2.1.1 Step 1: Log into Github to identify yourself to the Analytical Platform If you’re already logged into Github, you will not see the ‘Sign in to GitHub to continue to Analytics platform’ screen. 10.2.1.2 Step 2: Set up your 2FA using your smartphone Note: If you get the error ‘x’, you need to make sure that your phone’s clock is accurate. See here "]
]
